{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Reddit Bot\n",
    "\n",
    "from db import DbService, SaveJsonToFileStrategy\n",
    "from bot import RedditBot\n",
    "from services import ApiClient, Service\n",
    "from analysis import BertComparitor, PostComparisonProvider\n",
    "\n",
    "bot = RedditBot(\n",
    "            Service(\n",
    "                ApiClient = ApiClient(),\n",
    "                DbService = DbService(\n",
    "                         SaveJsonToFileStrategy())\n",
    "                    , analyzerService = PostComparisonProvider(BertComparitor('bert-base-nli-mean-tokens'))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "posts[1]:  ['Help with XML button', 'https://www.reddit.com/r/ProgrammingBuddies/comments/w6skn0/help_with_xml_button/', \"Hi how are you?\\n\\nI'm having trouble making a button that when I press it, I download a table with the information in XML format. I am using jquery, AJAX calls and a base in SQL to bring the information, how would you proceed to do it? \\n\\nps: the system architecture is MVC.\\n\\n Thanks!\", 1, 1658658605.0, 'w6skn0']\n"
     ]
    }
   ],
   "source": [
    "df = bot.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>created</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Help with XML button</td>\n",
       "      <td>https://www.reddit.com/r/ProgrammingBuddies/co...</td>\n",
       "      <td>Hi how are you?\\n\\nI'm having trouble making a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1658658605.0</td>\n",
       "      <td>w6skn0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Android Development with Kotlin</td>\n",
       "      <td>https://www.reddit.com/r/ProgrammingBuddies/co...</td>\n",
       "      <td>Hello. I am a beginner to Android Development ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1658648653.0</td>\n",
       "      <td>w6q635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Programming Python trading bot</td>\n",
       "      <td>https://www.reddit.com/r/ProgrammingBuddies/co...</td>\n",
       "      <td>I am currently working on a python trading bot...</td>\n",
       "      <td>2</td>\n",
       "      <td>1658601696.0</td>\n",
       "      <td>w6b00j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Looking for people to study game engine progra...</td>\n",
       "      <td>https://www.reddit.com/r/ProgrammingBuddies/co...</td>\n",
       "      <td>Hi, add me on discord if interested : Rack Smi...</td>\n",
       "      <td>2</td>\n",
       "      <td>1658596562.0</td>\n",
       "      <td>w692v4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Need help getting out of a Support role and ge...</td>\n",
       "      <td>https://www.reddit.com/r/ProgrammingBuddies/co...</td>\n",
       "      <td>Hello! So I have currently been working in sup...</td>\n",
       "      <td>3</td>\n",
       "      <td>1658551989.0</td>\n",
       "      <td>w5v9ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>more web devs for projects</td>\n",
       "      <td>https://www.reddit.com/r/ProgrammingBuddies/co...</td>\n",
       "      <td>Looking for more members to join discord serve...</td>\n",
       "      <td>2</td>\n",
       "      <td>1656183202.0</td>\n",
       "      <td>vklpfo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>I'm looking for a programming buddy or couple ...</td>\n",
       "      <td>https://www.reddit.com/r/ProgrammingBuddies/co...</td>\n",
       "      <td>I'm just starting to learn C ++ and I think it...</td>\n",
       "      <td>13</td>\n",
       "      <td>1656123127.0</td>\n",
       "      <td>vk4gvk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Hey guys. So I am looking for someone who can ...</td>\n",
       "      <td>https://www.reddit.com/r/ProgrammingBuddies/co...</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>1656073569.0</td>\n",
       "      <td>vjn9v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Beginner looking for someone to work on DS/ML ...</td>\n",
       "      <td>https://www.reddit.com/r/ProgrammingBuddies/co...</td>\n",
       "      <td>Hello!\\n\\nI am 17 and a senior in HS, took a p...</td>\n",
       "      <td>2</td>\n",
       "      <td>1656027417.0</td>\n",
       "      <td>vjacu6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Looking for someone to practice and learn prog...</td>\n",
       "      <td>https://www.reddit.com/r/ProgrammingBuddies/co...</td>\n",
       "      <td>I recently just got into coding (Web developme...</td>\n",
       "      <td>0</td>\n",
       "      <td>1656006063.0</td>\n",
       "      <td>vj2jbl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                                 Help with XML button   \n",
       "1                      Android Development with Kotlin   \n",
       "2                       Programming Python trading bot   \n",
       "3    Looking for people to study game engine progra...   \n",
       "4    Need help getting out of a Support role and ge...   \n",
       "..                                                 ...   \n",
       "144                         more web devs for projects   \n",
       "145  I'm looking for a programming buddy or couple ...   \n",
       "146  Hey guys. So I am looking for someone who can ...   \n",
       "147  Beginner looking for someone to work on DS/ML ...   \n",
       "148  Looking for someone to practice and learn prog...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://www.reddit.com/r/ProgrammingBuddies/co...   \n",
       "1    https://www.reddit.com/r/ProgrammingBuddies/co...   \n",
       "2    https://www.reddit.com/r/ProgrammingBuddies/co...   \n",
       "3    https://www.reddit.com/r/ProgrammingBuddies/co...   \n",
       "4    https://www.reddit.com/r/ProgrammingBuddies/co...   \n",
       "..                                                 ...   \n",
       "144  https://www.reddit.com/r/ProgrammingBuddies/co...   \n",
       "145  https://www.reddit.com/r/ProgrammingBuddies/co...   \n",
       "146  https://www.reddit.com/r/ProgrammingBuddies/co...   \n",
       "147  https://www.reddit.com/r/ProgrammingBuddies/co...   \n",
       "148  https://www.reddit.com/r/ProgrammingBuddies/co...   \n",
       "\n",
       "                                                  body score       created  \\\n",
       "0    Hi how are you?\\n\\nI'm having trouble making a...     1  1658658605.0   \n",
       "1    Hello. I am a beginner to Android Development ...     2  1658648653.0   \n",
       "2    I am currently working on a python trading bot...     2  1658601696.0   \n",
       "3    Hi, add me on discord if interested : Rack Smi...     2  1658596562.0   \n",
       "4    Hello! So I have currently been working in sup...     3  1658551989.0   \n",
       "..                                                 ...   ...           ...   \n",
       "144  Looking for more members to join discord serve...     2  1656183202.0   \n",
       "145  I'm just starting to learn C ++ and I think it...    13  1656123127.0   \n",
       "146                                                        6  1656073569.0   \n",
       "147  Hello!\\n\\nI am 17 and a senior in HS, took a p...     2  1656027417.0   \n",
       "148  I recently just got into coding (Web developme...     0  1656006063.0   \n",
       "\n",
       "         id  \n",
       "0    w6skn0  \n",
       "1    w6q635  \n",
       "2    w6b00j  \n",
       "3    w692v4  \n",
       "4    w5v9ea  \n",
       "..      ...  \n",
       "144  vklpfo  \n",
       "145  vk4gvk  \n",
       "146  vjn9v2  \n",
       "147  vjacu6  \n",
       "148  vj2jbl  \n",
       "\n",
       "[149 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/galzafar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/galzafar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/galzafar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/galzafar/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cleanup(text):\n",
    "  # Convert to lowercase.\n",
    "  text = text.lower()     \n",
    "\n",
    "  # Remove everything but letters and spaces.\n",
    "  text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "\n",
    "  # Remove single letters.\n",
    "  text = re.sub(r'(^\\w\\s)|(\\s\\w\\s)|(\\s\\w$)', ' ', text)\n",
    "\n",
    "  # Converge multiple spaces into one.\n",
    "  text = re.sub(r'\\s+', ' ', text) \n",
    "\n",
    "  # Remove trailing and leading spaces.    \n",
    "  text = text.strip()\n",
    "\n",
    "  return text\n",
    "\n",
    "\n",
    "  # Since we found only 6 rows with emojis we decided to remove them.\n",
    "def remove_emojis(text):\n",
    "  return emoji.replace_emoji(text)\n",
    "\n",
    "def remove_urls(text):\n",
    "  return re.sub('http(s?)://[^\\s]+', ' ', text)\n",
    "\n",
    "def decode_html_entities(text):\n",
    "  return html.unescape(text)\n",
    "\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "  eng_stop_words = stopwords.words('english')\n",
    "  non_stop_words = [word for word in text.split() if word not in eng_stop_words]\n",
    "  return ' '.join(non_stop_words)   \n",
    "\n",
    "\n",
    "\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "# This is a helper function to map NTLK position tags\n",
    "def get_wordnet_pos(text):\n",
    "    if text.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif text.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif text.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif text.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize(text):\n",
    "    # Split the text to words and get the part of speach (pos) of each \n",
    "    # of the words (i.e. noun, verb, etc.)\n",
    "    words = word_tokenize(text)\n",
    "    words_with_pos = nltk.pos_tag(words) \n",
    "    \n",
    "    # Lemmatize each word.\n",
    "    res = []\n",
    "    for x in words_with_pos:\n",
    "      word = x[0]\n",
    "      pos = x[1]\n",
    "      res.append(wl.lemmatize(word, get_wordnet_pos(pos)))\n",
    "\n",
    "    return \" \".join(res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "  text = remove_urls(text)  \n",
    "  text = remove_emojis(text)\n",
    "  text = decode_html_entities(text)\n",
    "  text = simple_cleanup(text)\n",
    "  text = remove_stopwords(text)\n",
    "  text = lemmatize(text)\n",
    "  return text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['title'] + ' ' + df['body']\n",
    "df['text'] = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'bert-base-nli-mean-tokens'\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "text_embeddings = model.encode(df['text'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_similarities=cosine_similarity(text_embeddings)\n",
    "pairwise_differences=euclidean_distances(text_embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity_matrix = pd.DataFrame(pairwise_similarities, columns=range(pairwise_similarities.shape[0]), index=range(pairwise_similarities.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56   56     1.000000\n",
       "71   71     1.000000\n",
       "92   92     1.000000\n",
       "104  104    1.000000\n",
       "148  148    1.000000\n",
       "              ...   \n",
       "146  7      0.168673\n",
       "96   7      0.149337\n",
       "7    96     0.149337\n",
       "128  7      0.118306\n",
       "7    128    0.118306\n",
       "Length: 22201, dtype: float32"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import float32\n",
    "\n",
    "\n",
    "s = df_similarity_matrix.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)\n",
    "\n",
    "so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_so = pd.DataFrame(so, columns=['similarity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22052, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11016, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "df_so = pd.DataFrame(so, columns=['similarity'])\n",
    "\n",
    "# dataframe drop values with similarity around 1.0\n",
    "mask = df_so['similarity'].apply(lambda x: not math.isclose(x, 1.0, rel_tol=0.01))\n",
    "df_so = df_so[mask]\n",
    "print(df_so.shape)\n",
    "# drop duplicates based on similarity value\n",
    "df_so = df_so.drop_duplicates(subset=['similarity'], keep='first')\n",
    "df_so.shape\n",
    "#df_so\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
